# This is a Docker Compose file for setting up Ollama and Open-WebUI with GPU support.
services:
  ollama:
      container_name: ollama
      image: ollama/ollama3.2:3b
      restart: unless-stopped
      networks:
        ai-net:
          ipv4_address: 172.20.0.10
      ports:
        - "11434:11434"
      volumes:
        - ollama:/root/.ollama3
      deploy:
        resources:
          reservations:
            devices:
              - capabilities: [gpu]
  
  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:cuda
    restart: unless-stopped
    networks:
      ai-net:
        ipv4_address: 172.20.0.11
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - open-webui:/app/backend/data
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

volumes:
  ollama:
  open-webui:

networks:
  ai-net:
    driver: bridge
    driver_opts:
      com.docker.networks.bridge.enable_icc: "true"
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
